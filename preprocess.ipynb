{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24fc291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3dfed9",
   "metadata": {},
   "source": [
    "## Preprocessing images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee2deb",
   "metadata": {},
   "source": [
    "#### Loading previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c26323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an array of positive and negative labelled datasets\n",
    "\n",
    "sample_data_limit = 200\n",
    "\n",
    "all_data = pd.read_csv(\"sample_data.csv\")\n",
    "numpy_array = all_data.values\n",
    "\n",
    "positives, negatives = ([], [])\n",
    "\n",
    "iter = 0\n",
    "while(len(positives) < sample_data_limit or len(negatives) < sample_data_limit):\n",
    "    label = numpy_array[iter][3]\n",
    "    if label == 1:\n",
    "        positives.append(tuple(numpy_array[iter][1:]))\n",
    "    else:\n",
    "        negatives.append(tuple(numpy_array[iter][1:]))\n",
    "        \n",
    "    iter += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6470ae",
   "metadata": {},
   "source": [
    "#### Resize images to (105, 105) and scale from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38448d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert image to (105, 105)\n",
    "def preprocess(image_path):\n",
    "    byte_image = tf.io.read_file(image_path)\n",
    "#     print(byte_image)\n",
    "    img = tf.io.decode_jpeg(byte_image)\n",
    "#     print(img)\n",
    "#     plt.imshow(img)\n",
    "    img = tf.image.resize(img, (105, 105))\n",
    "\n",
    "    img = img / 255.0 \n",
    "#     plt.imshow(img)\n",
    "    #     plt.n\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed91b4b",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1364474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.7\n",
    "\n",
    "# Training partition\n",
    "train_data = data.take(round(len(data)*split_ratio))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)\n",
    "\n",
    "# Testing partition\n",
    "test_data = data.skip(round(len(data)*split_ratio))\n",
    "test_data = test_data.take(round(len(data)*(1-split_ratio)))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd527a95",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85d03db",
   "metadata": {},
   "source": [
    "#### Making Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a80a4473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 105, 105, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 96, 96, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 48, 48, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 42, 42, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 21, 21, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 18, 18, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 9, 9, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38960448 (148.62 MB)\n",
      "Trainable params: 38960448 (148.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def make_embedding(): \n",
    "    inp = Input(shape=(105,105,3), name='input_image')\n",
    "    \n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "    \n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    # Third block \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')\n",
    "\n",
    "embedding = make_embedding()\n",
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87b3818",
   "metadata": {},
   "source": [
    "#### Making Distance Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00a18e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance class\n",
    "class L1Dist(Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Magic happens here - similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28e0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e203f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_getter = train_data.as_numpy_iterator()\n",
    "# train_sample = train_data_getter.next();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f38e32",
   "metadata": {},
   "source": [
    "#### Making Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e064da9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# siamese_model = make_siamese_model()\n",
    "\n",
    "siamese_model = tf.keras.models.load_model('siamese_modelv2.h5', \n",
    "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17ddf2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SiameseNetwork\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_img (InputLayer)      [(None, 105, 105, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " validation_img (InputLayer  [(None, 105, 105, 3)]        0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)      (None, 4096)                 3896044   ['input_img[0][0]',           \n",
      "                                                          8          'validation_img[0][0]']      \n",
      "                                                                                                  \n",
      " l1_dist_2 (L1Dist)          (None, 4096)                 0         ['embedding[0][0]',           \n",
      "                                                                     'embedding[1][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    4097      ['l1_dist_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38964545 (148.64 MB)\n",
      "Trainable params: 38964545 (148.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3dbbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "433640c8",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9626974",
   "metadata": {},
   "source": [
    "##### Setting up loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d123182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36838242",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.legacy.Adam(1e-4) # 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469a2c9",
   "metadata": {},
   "source": [
    "##### Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "092c8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff5525",
   "metadata": {},
   "source": [
    "##### Train step function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacd25d3",
   "metadata": {},
   "source": [
    "##### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f797b1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736454f",
   "metadata": {},
   "source": [
    "##### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b7baad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84794910",
   "metadata": {},
   "source": [
    "#### Evaluating Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecd4f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "658b564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7d1e122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1 if prediction > 0.5 else 0 for prediction in y_hat ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a996d4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679db8fd",
   "metadata": {},
   "source": [
    "#### Calculating Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f168c39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m= Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30ff7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.update_state(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e621fb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4193d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bfe96f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.update_state(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "afe0f2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2614738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a173d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267cd257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
